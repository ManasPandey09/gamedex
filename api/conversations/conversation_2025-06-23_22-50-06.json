[
  {
    "role": "user",
    "content": "how do i connect langchain and chroma chroma db"
  },
  {
    "role": "assistant",
    "content": null
  },
  {
    "role": "user",
    "content": [
      {
        "type": "text",
        "text": "Tool result for `get_docs`:\n\n\n\n\n\nChroma | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsVector storesChromaOn this pageChroma\nThis notebook covers how to get started with the Chroma vector store.\n\nChroma is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of Chroma at this page, and find the API reference for the LangChain integration at this page.\n\nSetup\u200b\nTo access Chroma vector stores you'll need to install the langchain-chroma integration package.\npip install -qU \"langchain-chroma>=0.1.2\"\nCredentials\u200b\nYou can use the Chroma vector store without any credentials, simply installing the package above is enough!\nIf you want to get best in-class automated tracing of your model calls you can also set your LangSmith API key by uncommenting below:\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\nInitialization\u200b\nBasic Initialization\u200b\nBelow is a basic initialization, including the use of a directory to save the data locally.\n\nSelect embeddings model:OpenAI\u25beOpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get(\"OPENAI_API_KEY\"):  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\nfrom langchain_chroma import Chromavector_store = Chroma(    collection_name=\"example_collection\",    embedding_function=embeddings,    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary)\nInitialization from client\u200b\nYou can also initialize from a Chroma client, which is particularly useful if you want easier access to the underlying database.\nimport chromadbpersistent_client = chromadb.PersistentClient()collection = persistent_client.get_or_create_collection(\"collection_name\")collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])vector_store_from_client = Chroma(    client=persistent_client,    collection_name=\"collection_name\",    embedding_function=embeddings,)\nManage vector store\u200b\nOnce you have created your vector store, we can interact with it by adding and deleting different items.\nAdd items to vector store\u200b\nWe can add items to our vector store by using the add_documents function.\nfrom uuid import uuid4from langchain_core.documents import Documentdocument_1 = Document(    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",    metadata={\"source\": \"tweet\"},    id=1,)document_2 = Document(    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",    metadata={\"source\": \"news\"},    id=2,)document_3 = Document(    page_content=\"Building an exciting new project with LangChain - come check it out!\",    metadata={\"source\": \"tweet\"},    id=3,)document_4 = Document(    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",    metadata={\"source\": \"news\"},    id=4,)document_5 = Document(    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",    metadata={\"source\": \"tweet\"},    id=5,)document_6 = Document(    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",    metadata={\"source\": \"website\"},    id=6,)document_7 = Document(    page_content=\"The top 10 soccer players in the world right now.\",    metadata={\"source\": \"website\"},    id=7,)document_8 = Document(    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",    metadata={\"source\": \"tweet\"},    id=8,)document_9 = Document(    page_content=\"The stock market is down 500 points today due to fears of a recession.\",    metadata={\"source\": \"news\"},    id=9,)document_10 = Document(    page_content=\"I have a bad feeling I am going to get deleted :(\",    metadata={\"source\": \"tweet\"},    id=10,)documents = [    document_1,    document_2,    document_3,    document_4,    document_5,    document_6,    document_7,    document_8,    document_9,    document_10,]uuids = [str(uuid4()) for _ in range(len(documents))]vector_store.add_documents(documents=documents, ids=uuids)API Reference:Document\n['f22ed484-6db3-4b76-adb1-18a777426cd6', 'e0d5bab4-6453-4511-9a37-023d9d288faa', '877d76b8-3580-4d9e-a13f-eed0fa3d134a', '26eaccab-81ce-4c0a-8e76-bf542647df18', 'bcaa8239-7986-4050-bf40-e14fb7dab997', 'cdc44b38-a83f-4e49-b249-7765b334e09d', 'a7a35354-2687-4bc2-8242-3849a4d18d34', '8780caf1-d946-4f27-a707-67d037e9e1d8', 'dec6af2a-7326-408f-893d-7d7d717dfda9', '3b18e210-bb59-47a0-8e17-c8e51176ea5e']\nUpdate items in vector store\u200b\nNow that we have added documents to our vector store, we can update existing documents by using the update_documents function.\nupdated_document_1 = Document(    page_content=\"I had chocolate chip pancakes and fried eggs for breakfast this morning.\",    metadata={\"source\": \"tweet\"},    id=1,)updated_document_2 = Document(    page_content=\"The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees.\",    metadata={\"source\": \"news\"},    id=2,)vector_store.update_document(document_id=uuids[0], document=updated_document_1)# You can also update multiple documents at oncevector_store.update_documents(    ids=uuids[:2], documents=[updated_document_1, updated_document_2])\nDelete items from vector store\u200b\nWe can also delete items from our vector store as follows:\nvector_store.delete(ids=uuids[-1])\nQuery vector store\u200b\nOnce your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.\nQuery directly\u200b\nSimilarity search\u200b\nPerforming a simple similarity search can be done as follows:\nresults = vector_store.similarity_search(    \"LangChain provides abstractions to make working with LLMs easy\",    k=2,    filter={\"source\": \"tweet\"},)for res in results:    print(f\"* {res.page_content} [{res.metadata}]\")\n* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\nSimilarity search with score\u200b\nIf you want to execute a similarity search and receive the corresponding scores you can run:\nresults = vector_store.similarity_search_with_score(    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"})for res, score in results:    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")\n* [SIM=1.726390] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\nSearch by vector\u200b\nYou can also search by vector:\nresults = vector_store.similarity_search_by_vector(    embedding=embeddings.embed_query(\"I love green eggs and ham!\"), k=1)for doc in results:    print(f\"* {doc.page_content} [{doc.metadata}]\")\n* I had chocolate chip pancakes and fried eggs for breakfast this morning. [{'source': 'tweet'}]\nOther search methods\u200b\nThere are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for AstraDBVectorStore check out the API reference.\nQuery by turning into retriever\u200b\nYou can also transform the vector store into a retriever for easier usage in your chains. For more information on the different search types and kwargs you can pass, please visit the API reference here.\nretriever = vector_store.as_retriever(    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5})retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})\n[Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]\nUsage for retrieval-augmented generation\u200b\nFor guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n\nTutorials\nHow-to: Question and answer with RAG\nRetrieval conceptual docs\n\nAPI reference\u200b\nFor detailed documentation of all Chroma vector store features and configurations head to the API reference: https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html\nRelated\u200b\n\nVector store conceptual guide\nVector store how-to guides\nEdit this pageWas this page helpful?PreviousApache CassandraNextClarifaiSetupCredentialsInitializationBasic InitializationInitialization from clientManage vector storeAdd items to vector storeUpdate items in vector storeDelete items from vector storeQuery vector storeQuery directlyQuery by turning into retrieverUsage for retrieval-augmented generationAPI referenceRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nChroma | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversDeep LakeAstra DBChromaDashVectorDatabricks Vector SearchDingoDBElasticsearchSAP HANA Cloud Vector EngineMilvusMongoDB AtlasMyScaleNeo4jOpenSearchPGVector (Postgres)PineconeQdrantRedisSupabase (Postgres)Tencent Cloud VectorDBTimescale Vector (Postgres)Vectara self-queryingWeaviateSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsRetrieversSelf-querying retrieversChromaOn this pageChroma\n\nChroma is a vector database for building AI applications with embeddings.\n\nIn the notebook, we'll demo the SelfQueryRetriever wrapped around a Chroma vector store.\nCreating a Chroma vector store\u200b\nFirst we'll want to create a Chroma vector store and seed it with some data. We've created a small demo set of documents that contain summaries of movies.\nNote: The self-query retriever requires you to have lark installed (pip install lark). We also need the langchain-chroma package.\n%pip install --upgrade --quiet  lark\n%pip install --upgrade --quiet  langchain-chroma\nWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.\nimport getpassimport osif \"OPENAI_API_KEY\" not in os.environ:    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\nOpenAI API Key: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nfrom langchain_chroma import Chromafrom langchain_core.documents import Documentfrom langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings()API Reference:Document | OpenAIEmbeddings\ndocs = [    Document(        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},    ),    Document(        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},    ),    Document(        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},    ),    Document(        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},    ),    Document(        page_content=\"Toys come alive and have a blast doing so\",        metadata={\"year\": 1995, \"genre\": \"animated\"},    ),    Document(        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",        metadata={            \"year\": 1979,            \"director\": \"Andrei Tarkovsky\",            \"genre\": \"science fiction\",            \"rating\": 9.9,        },    ),]vectorstore = Chroma.from_documents(docs, embeddings)\nUsing embedded DuckDB without persistence: data will be transient\nCreating our self-querying retriever\u200b\nNow we can instantiate our retriever. To do this we'll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents.\nfrom langchain.chains.query_constructor.schema import AttributeInfofrom langchain.retrievers.self_query.base import SelfQueryRetrieverfrom langchain_openai import OpenAImetadata_field_info = [    AttributeInfo(        name=\"genre\",        description=\"The genre of the movie\",        type=\"string or list[string]\",    ),    AttributeInfo(        name=\"year\",        description=\"The year the movie was released\",        type=\"integer\",    ),    AttributeInfo(        name=\"director\",        description=\"The name of the movie director\",        type=\"string\",    ),    AttributeInfo(        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"    ),]document_content_description = \"Brief summary of a movie\"llm = OpenAI(temperature=0)retriever = SelfQueryRetriever.from_llm(    llm, vectorstore, document_content_description, metadata_field_info, verbose=True)API Reference:AttributeInfo | SelfQueryRetriever | OpenAI\nTesting it out\u200b\nAnd now we can try actually using our retriever!\n# This example only specifies a relevant queryretriever.invoke(\"What are some movies about dinosaurs\")\nquery='dinosaur' filter=None\n[Document(page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose', metadata={'year': 1993, 'rating': 7.7, 'genre': 'science fiction'}), Document(page_content='Toys come alive and have a blast doing so', metadata={'year': 1995, 'genre': 'animated'}), Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}), Document(page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...', metadata={'year': 2010, 'director': 'Christopher Nolan', 'rating': 8.2})]\n# This example only specifies a filterretriever.invoke(\"I want to watch a movie rated higher than 8.5\")\nquery=' ' filter=Comparison(comparator=<Comparator.GT: 'gt'>, attribute='rating', value=8.5)\n[Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}), Document(page_content='Three men walk into the Zone, three men walk out of the Zone', metadata={'year': 1979, 'rating': 9.9, 'director': 'Andrei Tarkovsky', 'genre': 'science fiction'})]\n# This example specifies a query and a filterretriever.invoke(\"Has Greta Gerwig directed any movies about women\")\nquery='women' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='director', value='Greta Gerwig')\n[Document(page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them', metadata={'year': 2019, 'director': 'Greta Gerwig', 'rating': 8.3})]\n# This example specifies a composite filterretriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")\nquery=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='genre', value='science fiction'), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='rating', value=8.5)])\n[Document(page_content='Three men walk into the Zone, three men walk out of the Zone', metadata={'year': 1979, 'rating': 9.9, 'director': 'Andrei Tarkovsky', 'genre': 'science fiction'})]\n# This example specifies a query and composite filterretriever.invoke(    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\")\nquery='toys' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GT: 'gt'>, attribute='year', value=1990), Comparison(comparator=<Comparator.LT: 'lt'>, attribute='year', value=2005), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='genre', value='animated')])\n[Document(page_content='Toys come alive and have a blast doing so', metadata={'year': 1995, 'genre': 'animated'})]\nFilter k\u200b\nWe can also use the self query retriever to specify k: the number of documents to fetch.\nWe can do this by passing enable_limit=True to the constructor.\nretriever = SelfQueryRetriever.from_llm(    llm,    vectorstore,    document_content_description,    metadata_field_info,    enable_limit=True,    verbose=True,)\n# This example only specifies a relevant queryretriever.invoke(\"what are two movies about dinosaurs\")\nquery='dinosaur' filter=None\n[Document(page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose', metadata={'year': 1993, 'rating': 7.7, 'genre': 'science fiction'}), Document(page_content='Toys come alive and have a blast doing so', metadata={'year': 1995, 'genre': 'animated'}), Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}), Document(page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...', metadata={'year': 2010, 'director': 'Christopher Nolan', 'rating': 8.2})]Edit this pageWas this page helpful?PreviousAstra DBNextDashVectorCreating a Chroma vector storeCreating our self-querying retrieverTesting it outFilter kCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nChroma | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherProvidersMoreChromaOn this pageChroma\n\nChroma is a database for building AI applications with embeddings.\n\nInstallation and Setup\u200b\npip install langchain-chroma\nVectorStore\u200b\nThere exists a wrapper around Chroma vector databases, allowing you to use it as a vectorstore,\nwhether for semantic search or example selection.\nfrom langchain_chroma import Chroma\nFor a more detailed walkthrough of the Chroma wrapper, see this notebook\nRetriever\u200b\nSee a usage example.\nfrom langchain.retrievers import SelfQueryRetrieverAPI Reference:SelfQueryRetrieverEdit this pageWas this page helpful?PreviousChaindeskNextClarifaiInstallation and SetupVectorStoreRetrieverCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nHow to create and query vector stores | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to create and query vector storesOn this pageHow to create and query vector stores\ninfoHead to Integrations for documentation on built-in integrations with 3rd-party vector stores.\nOne of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding\nvectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are\n'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search\nfor you.\nGet started\u200b\nThis guide showcases basic functionality related to vector stores. A key part of working with vector stores is creating the vector to put in them,\nwhich is usually created via embeddings. Therefore, it is recommended that you familiarize yourself with the text embedding model interfaces before diving into this.\nBefore using the vectorstore at all, we need to load some data and initialize an embedding model.\nWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.\nimport osimport getpassos.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\nfrom langchain_community.document_loaders import TextLoaderfrom langchain_openai import OpenAIEmbeddingsfrom langchain_text_splitters import CharacterTextSplitter# Load the document, split it into chunks, embed each chunk and load it into the vector store.raw_documents = TextLoader('state_of_the_union.txt').load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)documents = text_splitter.split_documents(raw_documents)API Reference:TextLoader | OpenAIEmbeddings | CharacterTextSplitter\n\nThere are many great vector store options, here are a few that are free, open-source, and run entirely on your local machine. Review all integrations for many great hosted offerings.\nChromaFAISSLanceThis walkthrough uses the chroma vector database, which runs on your local machine as a library.pip install langchain-chromafrom langchain_chroma import Chromadb = Chroma.from_documents(documents, OpenAIEmbeddings())This walkthrough uses the FAISS vector database, which makes use of the Facebook AI Similarity Search (FAISS) library.pip install faiss-cpufrom langchain_community.vectorstores import FAISSdb = FAISS.from_documents(documents, OpenAIEmbeddings())API Reference:FAISSThis notebook shows how to use functionality related to the LanceDB vector database based on the Lance data format.pip install lancedbfrom langchain_community.vectorstores import LanceDBimport lancedbdb = lancedb.connect(\"/tmp/lancedb\")table = db.create_table(    \"my_table\",    data=[        {            \"vector\": embeddings.embed_query(\"Hello World\"),            \"text\": \"Hello World\",            \"id\": \"1\",        }    ],    mode=\"overwrite\",)db = LanceDB.from_documents(documents, OpenAIEmbeddings())API Reference:LanceDB\nSimilarity search\u200b\nAll vectorstores expose a similarity_search method.\nThis will take incoming documents, create an embedding of them, and then find all documents with the most similar embedding.\nquery = \"What did the president say about Ketanji Brown Jackson\"docs = db.similarity_search(query)print(docs[0].page_content)\n    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections.    Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.    One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.    And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\nSimilarity search by vector\u200b\nIt is also possible to do a search for documents similar to a given embedding vector using similarity_search_by_vector which accepts an embedding vector as a parameter instead of a string.\nembedding_vector = OpenAIEmbeddings().embed_query(query)docs = db.similarity_search_by_vector(embedding_vector)print(docs[0].page_content)\n    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections.    Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.    One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.    And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\nAsync Operations\u200b\nVector stores are usually run as a separate service that requires some IO operations, and therefore they might be called asynchronously. That gives performance benefits as you don't waste time waiting for responses from external services. That might also be important if you work with an asynchronous framework, such as FastAPI.\nLangChain supports async operation on vector stores. All the methods might be called using their async counterparts, with the prefix a, meaning async.\ndocs = await db.asimilarity_search(query)docs\n[Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.', metadata={'source': 'state_of_the_union.txt'}), Document(page_content='A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.', metadata={'source': 'state_of_the_union.txt'}), Document(page_content='And for our LGBTQ+ Americans, let\u2019s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn\u2019t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we\u2019ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I\u2019m offering a Unity Agenda for the Nation. Four big things we can do together.  \\n\\nFirst, beat the opioid epidemic.', metadata={'source': 'state_of_the_union.txt'}), Document(page_content='Tonight, I\u2019m announcing a crackdown on these companies overcharging American businesses and consumers. \\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \\n\\nThat ends on my watch. \\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \\n\\nWe\u2019ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \\n\\nLet\u2019s pass the Paycheck Fairness Act and paid leave.  \\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \\n\\nLet\u2019s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill\u2014our First Lady who teaches full-time\u2014calls America\u2019s best-kept secret: community colleges.', metadata={'source': 'state_of_the_union.txt'})]Edit this pageWas this page helpful?PreviousHow to trim messagesNextConceptual guideGet startedSimilarity searchSimilarity search by vectorAsync OperationsCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nVector stores | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsVector storesOn this pageVector stores\n\nA vector store stores embedded data and performs similarity search.\nSelect embedding model:\n\nSelect embeddings model:OpenAI\u25beOpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get(\"OPENAI_API_KEY\"):  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\nSelect vector store:\n\nSelect vector store:In-memory\u25beIn-memoryAstraDBChromaFAISSMilvusMongoDBPGVectorPineconeQdrantpip install -qU langchain-corefrom langchain_core.vectorstores import InMemoryVectorStorevector_store = InMemoryVectorStore(embeddings)\nVectorstoreDelete by IDFilteringSearch by VectorSearch with scoreAsyncPasses Standard TestsMulti TenancyIDs in add DocumentsAstraDBVectorStore\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cChroma\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cClickhouse\u2705\u2705\u274c\u2705\u274c\u274c\u274c\u274cCouchbaseVectorStore\u2705\u2705\u274c\u2705\u2705\u274c\u274c\u274cDatabricksVectorSearch\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cElasticsearchStore\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cFAISS\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cInMemoryVectorStore\u2705\u2705\u274c\u2705\u2705\u274c\u274c\u274cMilvus\u2705\u2705\u2705\u2705\u2705\u2705\u2705\u2705MongoDBAtlasVectorSearch\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274copenGauss\u2705\u2705\u2705\u2705\u274c\u2705\u274c\u2705PGVector\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cPineconeVectorStore\u2705\u2705\u2705\u274c\u2705\u274c\u274c\u274cQdrantVectorStore\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cRedis\u2705\u2705\u2705\u2705\u2705\u274c\u274c\u274cWeaviate\u2705\u2705\u2705\u2705\u2705\u274c\u2705\u274cSQLServer\u2705\u2705\u2705\u2705\u274c\u274c\u274c\u274c\nAll Vectorstores\u200b\nNameDescriptionActiveloop Deep LakeActiveloop Deep Lake as a Multi-Modal Vector Store that stores embedd...AerospikeAerospike Vector Search (AVS) is anAlibaba Cloud OpenSearchAlibaba Cloud Opensearch is a one-stop platform to develop intelligen...AnalyticDBAnalyticDB for PostgreSQL is a massively parallel processing (MPP) da...AnnoyAnnoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with P...Apache DorisApache Doris is a modern data warehouse for real-time analytics.ApertureDBApertureDB is a database that stores, indexes, and manages multi-moda...Astra DB Vector StoreThis page provides a quickstart for using Astra DB as a Vector Store.AtlasAtlas is a platform by Nomic made for interacting with both small and...AwaDBAwaDB is an AI Native database for the search and storage of embeddin...Azure Cosmos DB Mongo vCoreThis notebook shows you how to leverage this integrated vector databa...Azure Cosmos DB No SQLThis notebook shows you how to leverage this integrated vector databa...Azure AI SearchAzure AI Search (formerly known as Azure Search and Azure Cognitive S...BagelBagel (Open Inference platform for AI), is like GitHub for AI data.BagelDBBagelDB (Open Vector Database for AI), is like GitHub for AI data.Baidu Cloud ElasticSearch VectorSearchBaidu Cloud VectorSearch is a fully managed, enterprise-level distrib...Baidu VectorDBBaidu VectorDB is a robust, enterprise-level distributed database ser...Apache CassandraThis page provides a quickstart for using Apache Cassandra\u00ae as a Vect...ChromaThis notebook covers how to get started with the Chroma vector store.ClarifaiClarifai is an AI Platform that provides the full AI lifecycle rangin...ClickHouseClickHouse is the fastest and most resource efficient open-source dat...CloudflareVectorizeThis notebook covers how to get started with the CloudflareVectorize ...CouchbaseCouchbase is an award-winning distributed NoSQL cloud database that d...DashVectorDashVector is a fully-managed vectorDB service that supports high-dim...DatabricksDatabricks Vector Search is a serverless similarity search engine tha...DingoDBDingoDB is a distributed multi-mode vector database, which combines t...DocArray HnswSearchDocArrayHnswSearch is a lightweight Document Index implementation pro...DocArray InMemorySearchDocArrayInMemorySearch is a document index provided by Docarray that ...Amazon Document DBAmazon DocumentDB (with MongoDB Compatibility) makes it easy to set u...DuckDBThis notebook shows how to use DuckDB as a vector store.China Mobile ECloud ElasticSearch VectorSearchChina Mobile ECloud VectorSearch is a fully managed, enterprise-level...ElasticsearchElasticsearch is a distributed, RESTful search and analytics engine, ...EpsillaEpsilla is an open-source vector database that leverages the advanced...FaissFacebook AI Similarity Search (FAISS) is a library for efficient simi...Faiss (Async)Facebook AI Similarity Search (Faiss) is a library for efficient simi...FalkorDBVectorStoreFalkorDB is an open-source graph database with integrated support for...GelAn implementation of LangChain vectorstore abstraction using gel as t...Google AlloyDB for PostgreSQLAlloyDB is a fully managed relational database service that offers hi...Google BigQuery Vector SearchGoogle Cloud BigQuery Vector Search lets you use GoogleSQL to do sema...Google Cloud SQL for MySQLCloud SQL is a fully managed relational database service that offers ...Google Cloud SQL for PostgreSQLCloud SQL is a fully managed relational database service that offers ...FirestoreFirestore is a serverless document-oriented database that scales to m...Google Memorystore for RedisGoogle Memorystore for Redis is a fully-managed service that is power...Google SpannerSpanner is a highly scalable database that combines unlimited scalabi...Google Vertex AI Feature StoreGoogle Cloud Vertex Feature Store streamlines your ML feature managem...Google Vertex AI Vector SearchThis notebook shows how to use functionality related to the Google Cl...HippoTranswarp Hippo is an enterprise-level cloud-native distributed vecto...HologresHologres is a unified real-time data warehousing service developed by...InfinispanInfinispan is an open-source key-value data grid, it can work as sing...Jaguar Vector Database1. It is a distributed vector databaseKDB.AIKDB.AI is a powerful knowledge-based vector database and search engin...KineticaKinetica is a database with integrated support for vector similarity ...LanceDBLanceDB is an open-source database for vector-search built with persi...LanternLantern is an open-source vector similarity search for PostgresLindormThis notebook covers how to get started with the Lindorm vector store.LLMRailsLLMRails is a API platform for building GenAI applications. It provid...ManticoreSearch VectorStoreManticoreSearch is an open-source search engine that offers fast, sca...MariaDBLangChain's MariaDB integration (langchain-mariadb) provides vector c...MarqoThis notebook shows how to use functionality related to the Marqo vec...MeilisearchMeilisearch is an open-source, lightning-fast, and hyper relevant sea...Amazon MemoryDBVector Search introduction and langchain integration guide.MilvusMilvus is a database that stores, indexes, and manages massive embedd...Momento Vector Index (MVI)MVI: the most productive, easiest to use, serverless vector index for...MongoDB AtlasThis notebook covers how to MongoDB Atlas vector search in LangChain,...MyScaleMyScale is a cloud-based database optimized for AI applications and s...Neo4j Vector IndexNeo4j is an open-source graph database with integrated support for ve...NucliaDBYou can use a local NucliaDB instance or use Nuclia Cloud.OceanbaseThis notebook covers how to get started with the Oceanbase vector sto...openGaussThis notebook covers how to get started with the openGauss VectorStor...OpenSearchOpenSearch is a scalable, flexible, and extensible open-source softwa...Oracle AI Vector Search: Vector StoreOracle AI Vector Search is designed for Artificial Intelligence (AI) ...PathwayPathway is an open data processing framework. It allows you to easily...Postgres EmbeddingPostgres Embedding is an open-source vector similarity search for Pos...PGVecto.rsThis notebook shows how to use functionality related to the Postgres ...PGVectorAn implementation of LangChain vectorstore abstraction using postgres...PineconePinecone is a vector database with broad functionality.Pinecone (sparse)Pinecone is a vector database with broad functionality.QdrantQdrant (read: quadrant) is a vector similarity search engine. It prov...RedisThis notebook covers how to get started with the Redis vector store.RelytRelyt is a cloud native data warehousing service that is designed to ...RocksetRockset is a real-time search and analytics database built for the cl...SAP HANA Cloud Vector EngineSAP HANA Cloud Vector Engine is a vector store fully integrated into ...ScaNNScaNN (Scalable Nearest Neighbors) is a method for efficient vector s...SemaDBSemaDB from SemaFind is a no fuss vector similarity database for buil...SingleStoreSingleStore is a robust, high-performance distributed SQL database so...scikit-learnscikit-learn is an open-source collection of machine learning algorit...SQLiteVecThis notebook covers how to get started with the SQLiteVec vector sto...SQLite-VSSSQLite-VSS is an SQLite extension designed for vector search, emphasi...SQLServerAzure SQL provides a dedicated\u00a0Vector data type that simplifies the c...StarRocksStarRocks is a High-Performance Analytical Database.Supabase (Postgres)Supabase is an open-source Firebase alternative. Supabase is built on...SurrealDBSurrealDB is an end-to-end cloud-native database designed for modern ...TablestoreTablestore is a fully managed NoSQL cloud database service.TairTair is a cloud native in-memory database service developed by Alibab...Tencent Cloud VectorDBTencent Cloud VectorDB is a fully managed, self-developed, enterprise...ThirdAI NeuralDBNeuralDB is a CPU-friendly and fine-tunable vector store developed by...TiDB VectorTiDB Cloud, is a comprehensive Database-as-a-Service (DBaaS) solution...TigrisTigris is an open-source Serverless NoSQL Database and Search Platfor...TileDBTileDB is a powerful engine for indexing and querying dense and spars...Timescale Vector (Postgres)Timescale Vector is PostgreSQL++ vector database for AI applications.TypesenseTypesense is an open-source, in-memory search engine, that you can ei...Upstash VectorUpstash Vector is a serverless vector database designed for working w...USearchUSearch is a Smaller & Faster Single-File Vector Search EngineValdVald is a highly scalable distributed fast approximate nearest neighb...VDMSThis notebook covers how to get started with VDMS as a vector store.VearchVearch is the vector search infrastructure for deeping learning and A...VectaraVectara is the trusted AI Assistant and Agent platform which focuses ...VespaVespa is a fully featured search engine and vector database. It suppo...viking DBviking DB is a database that stores, indexes, and manages massive emb...vliteVLite is a simple and blazing fast vector database that allows you to...WeaviateThis notebook covers how to get started with the Weaviate vector stor...XataXata is a serverless data platform, based on PostgreSQL. It provides ...YDBYDB is a versatile open source Distributed SQL Database that combines...YellowbrickYellowbrick is an elastic, massively parallel processing (MPP) SQL da...ZepRecall, understand, and extract data from chat histories. Power perso...Zep CloudRecall, understand, and extract data from chat histories. Power perso...ZillizZilliz Cloud is a fully managed service on cloud for LF AI Milvus\u00ae,Edit this pageWas this page helpful?PreviousZeroxPDFLoaderNextVector storesAll VectorstoresCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nHow to retrieve using multiple vectors per document | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to retrieve using multiple vectors per documentOn this pageHow to retrieve using multiple vectors per document\nIt can often be useful to store multiple vectors per document. There are multiple use cases where this is beneficial. For example, we can embed multiple chunks of a document and associate those embeddings with the parent document, allowing retriever hits on the chunks to return the larger document.\nLangChain implements a base MultiVectorRetriever, which simplifies this process. Much of the complexity lies in how to create the multiple vectors per document. This notebook covers some of the common ways to create those vectors and use the MultiVectorRetriever.\nThe methods to create multiple vectors per document include:\n\nSmaller chunks: split a document into smaller chunks, and embed those (this is ParentDocumentRetriever).\nSummary: create a summary for each document, embed that along with (or instead of) the document.\nHypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.\n\nNote that this also enables another method of adding embeddings - manually. This is useful because you can explicitly add questions or queries that should lead to a document being recovered, giving you more control.\nBelow we walk through an example. First we instantiate some documents. We will index them in an (in-memory) Chroma vector store using OpenAI embeddings, but any LangChain vector store or embeddings model will suffice.\n%pip install --upgrade --quiet  langchain-chroma langchain langchain-openai > /dev/null\nfrom langchain.storage import InMemoryByteStorefrom langchain_chroma import Chromafrom langchain_community.document_loaders import TextLoaderfrom langchain_openai import OpenAIEmbeddingsfrom langchain_text_splitters import RecursiveCharacterTextSplitterloaders = [    TextLoader(\"paul_graham_essay.txt\"),    TextLoader(\"state_of_the_union.txt\"),]docs = []for loader in loaders:    docs.extend(loader.load())text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)docs = text_splitter.split_documents(docs)# The vectorstore to use to index the child chunksvectorstore = Chroma(    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings())API Reference:InMemoryByteStore | TextLoader | OpenAIEmbeddings | RecursiveCharacterTextSplitter\nSmaller chunks\u200b\nOften times it can be useful to retrieve larger chunks of information, but embed smaller chunks. This allows for embeddings to capture the semantic meaning as closely as possible, but for as much context as possible to be passed downstream. Note that this is what the ParentDocumentRetriever does. Here we show what is going on under the hood.\nWe will make a distinction between the vector store, which indexes embeddings of the (sub) documents, and the document store, which houses the \"parent\" documents and associates them with an identifier.\nimport uuidfrom langchain.retrievers.multi_vector import MultiVectorRetriever# The storage layer for the parent documentsstore = InMemoryByteStore()id_key = \"doc_id\"# The retriever (empty to start)retriever = MultiVectorRetriever(    vectorstore=vectorstore,    byte_store=store,    id_key=id_key,)doc_ids = [str(uuid.uuid4()) for _ in docs]API Reference:MultiVectorRetriever\nWe next generate the \"sub\" documents by splitting the original documents. Note that we store the document identifier in the metadata of the corresponding Document object.\n# The splitter to use to create smaller chunkschild_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)sub_docs = []for i, doc in enumerate(docs):    _id = doc_ids[i]    _sub_docs = child_text_splitter.split_documents([doc])    for _doc in _sub_docs:        _doc.metadata[id_key] = _id    sub_docs.extend(_sub_docs)\nFinally, we index the documents in our vector store and document store:\nretriever.vectorstore.add_documents(sub_docs)retriever.docstore.mset(list(zip(doc_ids, docs)))\nThe vector store alone will retrieve small chunks:\nretriever.vectorstore.similarity_search(\"justice breyer\")[0]\nDocument(page_content='Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.', metadata={'doc_id': '064eca46-a4c4-4789-8e3b-583f9597e54f', 'source': 'state_of_the_union.txt'})\nWhereas the retriever will return the larger parent document:\nlen(retriever.invoke(\"justice breyer\")[0].page_content)\n9875\nThe default search type the retriever performs on the vector database is a similarity search. LangChain vector stores also support searching via Max Marginal Relevance. This can be controlled via the search_type parameter of the retriever:\nfrom langchain.retrievers.multi_vector import SearchTyperetriever.search_type = SearchType.mmrlen(retriever.invoke(\"justice breyer\")[0].page_content)API Reference:SearchType\n9875\nAssociating summaries with a document for retrieval\u200b\nA summary may be able to distill more accurately what a chunk is about, leading to better retrieval. Here we show how to create summaries, and then embed those.\nWe construct a simple chain that will receive an input Document object and generate a summary using a LLM.\n\nSelect chat model:Google Gemini\u25beOpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelllm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\nimport uuidfrom langchain_core.documents import Documentfrom langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatechain = (    {\"doc\": lambda x: x.page_content}    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")    | llm    | StrOutputParser())API Reference:Document | StrOutputParser | ChatPromptTemplate\nNote that we can batch the chain across documents:\nsummaries = chain.batch(docs, {\"max_concurrency\": 5})\nWe can then initialize a MultiVectorRetriever as before, indexing the summaries in our vector store, and retaining the original documents in our document store:\n# The vectorstore to use to index the child chunksvectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())# The storage layer for the parent documentsstore = InMemoryByteStore()id_key = \"doc_id\"# The retriever (empty to start)retriever = MultiVectorRetriever(    vectorstore=vectorstore,    byte_store=store,    id_key=id_key,)doc_ids = [str(uuid.uuid4()) for _ in docs]summary_docs = [    Document(page_content=s, metadata={id_key: doc_ids[i]})    for i, s in enumerate(summaries)]retriever.vectorstore.add_documents(summary_docs)retriever.docstore.mset(list(zip(doc_ids, docs)))\n# # We can also add the original chunks to the vectorstore if we so want# for i, doc in enumerate(docs):#     doc.metadata[id_key] = doc_ids[i]# retriever.vectorstore.add_documents(docs)\nQuerying the vector store will return summaries:\nsub_docs = retriever.vectorstore.similarity_search(\"justice breyer\")sub_docs[0]\nDocument(page_content=\"President Biden recently nominated Judge Ketanji Brown Jackson to serve on the United States Supreme Court, emphasizing her qualifications and broad support. The President also outlined a plan to secure the border, fix the immigration system, protect women's rights, support LGBTQ+ Americans, and advance mental health services. He highlighted the importance of bipartisan unity in passing legislation, such as the Violence Against Women Act. The President also addressed supporting veterans, particularly those impacted by exposure to burn pits, and announced plans to expand benefits for veterans with respiratory cancers. Additionally, he proposed a plan to end cancer as we know it through the Cancer Moonshot initiative. President Biden expressed optimism about the future of America and emphasized the strength of the American people in overcoming challenges.\", metadata={'doc_id': '84015b1b-980e-400a-94d8-cf95d7e079bd'})\nWhereas the retriever will return the larger source document:\nretrieved_docs = retriever.invoke(\"justice breyer\")len(retrieved_docs[0].page_content)\n9194\nHypothetical Queries\u200b\nAn LLM can also be used to generate a list of hypothetical questions that could be asked of a particular document, which might bear close semantic similarity to relevant queries in a RAG application. These questions can then be embedded and associated with the documents to improve retrieval.\nBelow, we use the with_structured_output method to structure the LLM output into a list of strings.\nfrom typing import Listfrom pydantic import BaseModel, Fieldclass HypotheticalQuestions(BaseModel):    \"\"\"Generate hypothetical questions.\"\"\"    questions: List[str] = Field(..., description=\"List of questions\")chain = (    {\"doc\": lambda x: x.page_content}    # Only asking for 3 hypothetical questions, but this could be adjusted    | ChatPromptTemplate.from_template(        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer:\\n\\n{doc}\"    )    | ChatOpenAI(max_retries=0, model=\"gpt-4o\").with_structured_output(        HypotheticalQuestions    )    | (lambda x: x.questions))\nInvoking the chain on a single document demonstrates that it outputs a list of questions:\nchain.invoke(docs[0])\n[\"What impact did the IBM 1401 have on the author's early programming experiences?\", \"How did the transition from using the IBM 1401 to microcomputers influence the author's programming journey?\", \"What role did Lisp play in shaping the author's understanding and approach to AI?\"]\nWe can batch then batch the chain over all documents and assemble our vector store and document store as before:\n# Batch chain over documents to generate hypothetical questionshypothetical_questions = chain.batch(docs, {\"max_concurrency\": 5})# The vectorstore to use to index the child chunksvectorstore = Chroma(    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings())# The storage layer for the parent documentsstore = InMemoryByteStore()id_key = \"doc_id\"# The retriever (empty to start)retriever = MultiVectorRetriever(    vectorstore=vectorstore,    byte_store=store,    id_key=id_key,)doc_ids = [str(uuid.uuid4()) for _ in docs]# Generate Document objects from hypothetical questionsquestion_docs = []for i, question_list in enumerate(hypothetical_questions):    question_docs.extend(        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]    )retriever.vectorstore.add_documents(question_docs)retriever.docstore.mset(list(zip(doc_ids, docs)))\nNote that querying the underlying vector store will retrieve hypothetical questions that are semantically similar to the input query:\nsub_docs = retriever.vectorstore.similarity_search(\"justice breyer\")sub_docs\n[Document(page_content='What might be the potential benefits of nominating Circuit Court of Appeals Judge Ketanji Brown Jackson to the United States Supreme Court?', metadata={'doc_id': '43292b74-d1b8-4200-8a8b-ea0cb57fbcdb'}), Document(page_content='How might the Bipartisan Infrastructure Law impact the economic competition between the U.S. and China?', metadata={'doc_id': '66174780-d00c-4166-9791-f0069846e734'}), Document(page_content='What factors led to the creation of Y Combinator?', metadata={'doc_id': '72003c4e-4cc9-4f09-a787-0b541a65b38c'}), Document(page_content='How did the ability to publish essays online change the landscape for writers and thinkers?', metadata={'doc_id': 'e8d2c648-f245-4bcc-b8d3-14e64a164b64'})]\nAnd invoking the retriever will return the corresponding document:\nretrieved_docs = retriever.invoke(\"justice breyer\")len(retrieved_docs[0].page_content)\n9194Edit this pageWas this page helpful?PreviousHow to migrate from legacy LangChain agents to LangGraphNextHow to pass multimodal data to modelsSmaller chunksAssociating summaries with a document for retrievalHypothetical QueriesCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nSelf-querying retrievers | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)Bright DataBrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFeatherless AIFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AISmabblerGelGeopandasGitGitBookGitHubGitLabGOATGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK\u00f9zuLabel StudiolakeFSLanceDBLangChain Decorators \u2728LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLangfuse \ud83e\udea2LanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariaDBMariTalkMarqoMediaWikiDumpMeilisearchMemcachedMemgraphMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot\u00f6rheadMyScaleNAVERNebiusNeo4jNetmindNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesOxylabsPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRunpodRWKV-4SalesforceSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStore Integrationscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraValyu Deep SearchVDMSVearchVectaraVectorizeVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYDBYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflareWorkersAICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFeatherless AIFireworksChatFriendliGoodfireGoogle GeminiGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNebiusNetmindNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIQwen QwQRekaRunPod Chat ModelSambaNovaCloudSambaStudioChatSeekrFlowSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevectaravLLM ChatVolc Engine MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGContextual AI RerankerDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGalaxiaGoogle DriveGoogle Vertex AI SearchGraph RAGIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalNanoPQ (Product Quantization)NebiusneedleNimbleOutlinePermitPinecone Hybrid SearchPinecone RerankPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversDeep LakeAstra DBChromaDashVectorDatabricks Vector SearchDingoDBElasticsearchSAP HANA Cloud Vector EngineMilvusMongoDB AtlasMyScaleNeo4jOpenSearchPGVector (Postgres)PineconeQdrantRedisSupabase (Postgres)Tencent Cloud VectorDBTimescale Vector (Postgres)Vectara self-queryingWeaviateSVMTavilySearchAPITF-IDF**NeuralDB**ValyuContextVectorizeVespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchBrightDataWebScraperAPIBrightDataSERPBrightDataUnlockerCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitCompass DeFi ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGOATGolden QueryGoogle BooksGoogle Calendar ToolkitGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolHyperbrowser Browser Agent ToolsHyperbrowser Web Scraping ToolsIBM watsonx.aiIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemgraphMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNaver SearchNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryOxylabsPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraValyuContextVectaraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modeOutline Document LoaderPandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSingleStoreSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCloudflareVectorizeCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGelGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMariaDBMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseopenGaussOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconePinecone (sparse)QdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStorescikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYDBYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGoogle GeminiGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel\u00ae Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNebiusNetmindNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaNovaCloudSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsRetrieversSelf-querying retrieversSelf-querying retrievers\nLearn about how the self-querying retriever works here.\n\n\ud83d\udcc4\ufe0f Deep LakeDeep Lake is a multimodal database for building AI applications\ud83d\udcc4\ufe0f Astra DBDataStax Astra DB is a serverless\ud83d\udcc4\ufe0f ChromaChroma is a vector database for building AI applications with embeddings.\ud83d\udcc4\ufe0f DashVectorDashVector is a fully managed vector DB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.\ud83d\udcc4\ufe0f Databricks Vector SearchDatabricks Vector Search is a serverless similarity search engine that allows you to store a vector representation of your data, including metadata, in a vector database. With Vector Search, you can create auto-updating vector search indexes from Delta tables managed by Unity Catalog and query them with a simple API to return the most similar vectors.\ud83d\udcc4\ufe0f DingoDBDingoDB is a distributed multi-mode vector database, which combines the characteristics of data lakes and vector databases, and can store data of any type and size (Key-Value, PDF, audio, video, etc.). It has real-time low-latency processing capabilities to achieve rapid insight and response, and can efficiently conduct instant analysis and process multi-modal data.\ud83d\udcc4\ufe0f ElasticsearchElasticsearch is a distributed, RESTful search and analytics engine.\ud83d\udcc4\ufe0f SAP HANA Cloud Vector EngineFor more information on how to setup the SAP HANA vetor store, take a look at the documentation.\ud83d\udcc4\ufe0f MilvusMilvus is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.\ud83d\udcc4\ufe0f MongoDB AtlasMongoDB Atlas is a document database that can be\ud83d\udcc4\ufe0f MyScaleMyScale is an integrated vector database. You can access your database in SQL and also from here, LangChain.\ud83d\udcc4\ufe0f Neo4jNeo4j is a graph database that stores nodes and relationships, that also supports native vector search.\ud83d\udcc4\ufe0f OpenSearchOpenSearch is a scalable, flexible, and extensible open-source software suite for search, analytics, and observability applications licensed under Apache 2.0. OpenSearch is a distributed search and analytics engine based on Apache Lucene.\ud83d\udcc4\ufe0f PGVector (Postgres)PGVector is a vector similarity search package for Postgres data base.\ud83d\udcc4\ufe0f PineconePinecone is a vector database with broad functionality.\ud83d\udcc4\ufe0f QdrantQdrant (read: quadrant) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support.\ud83d\udcc4\ufe0f RedisRedis is an open-source key-value store that can be used as a cache, message broker, database, vector database and more.\ud83d\udcc4\ufe0f Supabase (Postgres)Supabase is an open-source Firebase alternative.\ud83d\udcc4\ufe0f Tencent Cloud VectorDBTencent Cloud VectorDB is a fully managed, self-developed, enterprise-level distributed database    service designed for storing, retrieving, and analyzing multi-dimensional vector data.\ud83d\udcc4\ufe0f Timescale Vector (Postgres)Timescale Vector is PostgreSQL++ for AI applications. It enables you to efficiently store and query billions of vector embeddings in PostgreSQL.\ud83d\udcc4\ufe0f Vectara self-queryingVectara is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.\ud83d\udcc4\ufe0f WeaviateWeaviate is an open-source vector database. It allows you to store data objects and vector embeddings fromEdit this pageWas this page helpful?PreviousSEC filingNextDeep LakeCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nHow to do \"self-querying\" retrieval | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to do \"self-querying\" retrievalOn this pageHow to do \"self-querying\" retrieval\ninfoHead to Integrations for documentation on vector stores with built-in support for self-querying.\nA self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query and then applies that structured query to its underlying vector store. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.\n\nGet started\u200b\nFor demonstration purposes we'll use a Chroma vector store. We've created a small demo set of documents that contain summaries of movies.\nNote: The self-query retriever requires you to have lark package installed.\n%pip install --upgrade --quiet  lark langchain-chroma\nfrom langchain_chroma import Chromafrom langchain_core.documents import Documentfrom langchain_openai import OpenAIEmbeddingsdocs = [    Document(        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},    ),    Document(        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},    ),    Document(        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},    ),    Document(        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},    ),    Document(        page_content=\"Toys come alive and have a blast doing so\",        metadata={\"year\": 1995, \"genre\": \"animated\"},    ),    Document(        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",        metadata={            \"year\": 1979,            \"director\": \"Andrei Tarkovsky\",            \"genre\": \"thriller\",            \"rating\": 9.9,        },    ),]vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())API Reference:Document | OpenAIEmbeddings\nCreating our self-querying retriever\u200b\nNow we can instantiate our retriever. To do this we'll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents.\nfrom langchain.chains.query_constructor.schema import AttributeInfofrom langchain.retrievers.self_query.base import SelfQueryRetrieverfrom langchain_openai import ChatOpenAImetadata_field_info = [    AttributeInfo(        name=\"genre\",        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",        type=\"string\",    ),    AttributeInfo(        name=\"year\",        description=\"The year the movie was released\",        type=\"integer\",    ),    AttributeInfo(        name=\"director\",        description=\"The name of the movie director\",        type=\"string\",    ),    AttributeInfo(        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"    ),]document_content_description = \"Brief summary of a movie\"llm = ChatOpenAI(temperature=0)retriever = SelfQueryRetriever.from_llm(    llm,    vectorstore,    document_content_description,    metadata_field_info,)API Reference:AttributeInfo | SelfQueryRetriever | ChatOpenAI\nTesting it out\u200b\nAnd now we can actually try using our retriever!\n# This example only specifies a filterretriever.invoke(\"I want to watch a movie rated higher than 8.5\")\n[Document(page_content='Three men walk into the Zone, three men walk out of the Zone', metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979}), Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006})]\n# This example specifies a query and a filterretriever.invoke(\"Has Greta Gerwig directed any movies about women\")\n[Document(page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them', metadata={'director': 'Greta Gerwig', 'rating': 8.3, 'year': 2019})]\n# This example specifies a composite filterretriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")\n[Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}), Document(page_content='Three men walk into the Zone, three men walk out of the Zone', metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979})]\n# This example specifies a query and composite filterretriever.invoke(    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\")\n[Document(page_content='Toys come alive and have a blast doing so', metadata={'genre': 'animated', 'year': 1995})]\nFilter k\u200b\nWe can also use the self query retriever to specify k: the number of documents to fetch.\nWe can do this by passing enable_limit=True to the constructor.\nretriever = SelfQueryRetriever.from_llm(    llm,    vectorstore,    document_content_description,    metadata_field_info,    enable_limit=True,)# This example only specifies a relevant queryretriever.invoke(\"What are two movies about dinosaurs\")\n[Document(page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose', metadata={'genre': 'science fiction', 'rating': 7.7, 'year': 1993}), Document(page_content='Toys come alive and have a blast doing so', metadata={'genre': 'animated', 'year': 1995})]\nConstructing from scratch with LCEL\u200b\nTo see what's going on under the hood, and to have more custom control, we can reconstruct our retriever from scratch.\nFirst, we need to create a query-construction chain. This chain will take a user query and generated a StructuredQuery object which captures the filters specified by the user. We provide some helper functions for creating a prompt and output parser. These have a number of tunable params that we'll ignore here for simplicity.\nfrom langchain.chains.query_constructor.base import (    StructuredQueryOutputParser,    get_query_constructor_prompt,)prompt = get_query_constructor_prompt(    document_content_description,    metadata_field_info,)output_parser = StructuredQueryOutputParser.from_components()query_constructor = prompt | llm | output_parserAPI Reference:StructuredQueryOutputParser | get_query_constructor_prompt\nLet's look at our prompt:\nprint(prompt.format(query=\"dummy question\"))\nYour goal is to structure the user's query to match the request schema provided below.<< Structured Request Schema >>When responding use a markdown code snippet with a JSON object formatted in the following schema:\\`\\`\\`json{    \"query\": string \\ text string to compare to document contents    \"filter\": string \\ logical condition statement for filtering documents}\\`\\`\\`The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.A logical condition statement is composed of one or more comparison and logical operation statements.A comparison statement takes the form: `comp(attr, val)`:- `comp` (eq | ne | gt | gte | lt | lte | contain | like | in | nin): comparator- `attr` (string):  name of attribute to apply the comparison to- `val` (string): is the comparison valueA logical operation statement takes the form `op(statement1, statement2, ...)`:- `op` (and | or | not): logical operator- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation toMake sure that you only use the comparators and logical operators listed above and no others.Make sure that filters only refer to attributes that exist in the data source.Make sure that filters only use the attributed names with its function names if there are functions applied on them.Make sure that filters only use format `YYYY-MM-DD` when handling date data typed values.Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.Make sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.<< Example 1. >>Data Source:\\`\\`\\`json{    \"content\": \"Lyrics of a song\",    \"attributes\": {        \"artist\": {            \"type\": \"string\",            \"description\": \"Name of the song artist\"        },        \"length\": {            \"type\": \"integer\",            \"description\": \"Length of the song in seconds\"        },        \"genre\": {            \"type\": \"string\",            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"        }    }}\\`\\`\\`User Query:What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genreStructured Request:\\`\\`\\`json{    \"query\": \"teenager love\",    \"filter\": \"and(or(eq(\\\"artist\\\", \\\"Taylor Swift\\\"), eq(\\\"artist\\\", \\\"Katy Perry\\\")), lt(\\\"length\\\", 180), eq(\\\"genre\\\", \\\"pop\\\"))\"}\\`\\`\\`<< Example 2. >>Data Source:\\`\\`\\`json{    \"content\": \"Lyrics of a song\",    \"attributes\": {        \"artist\": {            \"type\": \"string\",            \"description\": \"Name of the song artist\"        },        \"length\": {            \"type\": \"integer\",            \"description\": \"Length of the song in seconds\"        },        \"genre\": {            \"type\": \"string\",            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"        }    }}\\`\\`\\`User Query:What are songs that were not published on SpotifyStructured Request:\\`\\`\\`json{    \"query\": \"\",    \"filter\": \"NO_FILTER\"}\\`\\`\\`<< Example 3. >>Data Source:\\`\\`\\`json{    \"content\": \"Brief summary of a movie\",    \"attributes\": {    \"genre\": {        \"description\": \"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",        \"type\": \"string\"    },    \"year\": {        \"description\": \"The year the movie was released\",        \"type\": \"integer\"    },    \"director\": {        \"description\": \"The name of the movie director\",        \"type\": \"string\"    },    \"rating\": {        \"description\": \"A 1-10 rating for the movie\",        \"type\": \"float\"    }}}\\`\\`\\`User Query:dummy questionStructured Request:\nAnd what our full chain produces:\nquery_constructor.invoke(    {        \"query\": \"What are some sci-fi movies from the 90's directed by Luc Besson about taxi drivers\"    })\nStructuredQuery(query='taxi driver', filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='genre', value='science fiction'), Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='year', value=1990), Comparison(comparator=<Comparator.LT: 'lt'>, attribute='year', value=2000)]), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='director', value='Luc Besson')]), limit=None)\nThe query constructor is the key element of the self-query retriever. To make a great retrieval system you'll need to make sure your query constructor works well. Often this requires adjusting the prompt, the examples in the prompt, the attribute descriptions, etc. For an example that walks through refining a query constructor on some hotel inventory data, check out this cookbook.\nThe next key element is the structured query translator. This is the object responsible for translating the generic StructuredQuery object into a metadata filter in the syntax of the vector store you're using. LangChain comes with a number of built-in translators. To see them all head to the Integrations section.\nfrom langchain_community.query_constructors.chroma import ChromaTranslatorretriever = SelfQueryRetriever(    query_constructor=query_constructor,    vectorstore=vectorstore,    structured_query_translator=ChromaTranslator(),)API Reference:ChromaTranslator\nretriever.invoke(    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\")\n[Document(page_content='Toys come alive and have a blast doing so', metadata={'genre': 'animated', 'year': 1995})]Edit this pageWas this page helpful?PreviousHow to pass runtime secrets to runnablesNextHow to split text based on semantic similarityGet startedCreating our self-querying retrieverTesting it outFilter kConstructing from scratch with LCELCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nHow to use the MultiQueryRetriever | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to use the MultiQueryRetrieverOn this pageHow to use the MultiQueryRetriever\nDistance-based vector database retrieval embeds (represents) queries in high-dimensional space and finds similar embedded documents based on a distance metric. But, retrieval may produce different results with subtle changes in query wording, or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems, but can be tedious.\nThe MultiQueryRetriever automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the MultiQueryRetriever can mitigate some of the limitations of the distance-based retrieval and get a richer set of results.\nLet's build a vectorstore using the LLM Powered Autonomous Agents blog post by Lilian Weng from the RAG tutorial:\n# Build a sample vectorDBfrom langchain_chroma import Chromafrom langchain_community.document_loaders import WebBaseLoaderfrom langchain_openai import OpenAIEmbeddingsfrom langchain_text_splitters import RecursiveCharacterTextSplitter# Load blog postloader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")data = loader.load()# Splittext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)splits = text_splitter.split_documents(data)# VectorDBembedding = OpenAIEmbeddings()vectordb = Chroma.from_documents(documents=splits, embedding=embedding)API Reference:WebBaseLoader | OpenAIEmbeddings | RecursiveCharacterTextSplitter\nUSER_AGENT environment variable not set, consider setting it to identify your requests.\nSimple usage\u200b\nSpecify the LLM to use for query generation, and the retriever will do the rest.\nfrom langchain.retrievers.multi_query import MultiQueryRetrieverfrom langchain_openai import ChatOpenAIquestion = \"What are the approaches to Task Decomposition?\"llm = ChatOpenAI(temperature=0)retriever_from_llm = MultiQueryRetriever.from_llm(    retriever=vectordb.as_retriever(), llm=llm)API Reference:MultiQueryRetriever | ChatOpenAI\n# Set logging for the queriesimport logginglogging.basicConfig()logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\nunique_docs = retriever_from_llm.invoke(question)len(unique_docs)\nINFO:langchain.retrievers.multi_query:Generated queries: ['1. How can Task Decomposition be achieved through different methods?', '2. What strategies are commonly used for Task Decomposition?', '3. What are the various ways to break down tasks in Task Decomposition?']\n5\nNote that the underlying queries generated by the retriever are logged at the INFO level.\nSupplying your own prompt\u200b\nUnder the hood, MultiQueryRetriever generates queries using a specific prompt. To customize this prompt:\n\nMake a PromptTemplate with an input variable for the question;\nImplement an output parser like the one below to split the result into a list of queries.\n\nThe prompt and output parser together must support the generation of a list of queries.\nfrom typing import Listfrom langchain_core.output_parsers import BaseOutputParserfrom langchain_core.prompts import PromptTemplatefrom pydantic import BaseModel, Field# Output parser will split the LLM result into a list of queriesclass LineListOutputParser(BaseOutputParser[List[str]]):    \"\"\"Output parser for a list of lines.\"\"\"    def parse(self, text: str) -> List[str]:        lines = text.strip().split(\"\\n\")        return list(filter(None, lines))  # Remove empty linesoutput_parser = LineListOutputParser()QUERY_PROMPT = PromptTemplate(    input_variables=[\"question\"],    template=\"\"\"You are an AI language model assistant. Your task is to generate five     different versions of the given user question to retrieve relevant documents from a vector     database. By generating multiple perspectives on the user question, your goal is to help    the user overcome some of the limitations of the distance-based similarity search.     Provide these alternative questions separated by newlines.    Original question: {question}\"\"\",)llm = ChatOpenAI(temperature=0)# Chainllm_chain = QUERY_PROMPT | llm | output_parser# Other inputsquestion = \"What are the approaches to Task Decomposition?\"API Reference:BaseOutputParser | PromptTemplate\n# Runretriever = MultiQueryRetriever(    retriever=vectordb.as_retriever(), llm_chain=llm_chain, parser_key=\"lines\")  # \"lines\" is the key (attribute name) of the parsed output# Resultsunique_docs = retriever.invoke(\"What does the course say about regression?\")len(unique_docs)\nINFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide insights on regression from the course material?', '2. How is regression discussed in the course content?', '3. What information does the course offer regarding regression?', '4. In what way is regression covered in the course?', \"5. What are the course's teachings on regression?\"]\n9Edit this pageWas this page helpful?PreviousCustom Document LoaderNextHow to add scores to retriever resultsCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n\n\n\n\n\nHow to use the Parent Document Retriever | \ud83e\udd9c\ufe0f\ud83d\udd17 LangChain\n\n\n\n\n\n\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\ud83d\udcacSearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith\ud83e\udd9c\ud83d\udd78\ufe0f LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to use the Parent Document RetrieverOn this pageHow to use the Parent Document Retriever\nWhen splitting documents for retrieval, there are often conflicting desires:\n\nYou may want to have small documents, so that their embeddings can most\naccurately reflect their meaning. If too long, then the embeddings can\nlose meaning.\nYou want to have long enough documents that the context of each chunk is\nretained.\n\nThe ParentDocumentRetriever strikes that balance by splitting and storing\nsmall chunks of data. During retrieval, it first fetches the small chunks\nbut then looks up the parent ids for those chunks and returns those larger\ndocuments.\nNote that \"parent document\" refers to the document that a small chunk\noriginated from. This can either be the whole raw document OR a larger\nchunk.\nfrom langchain.retrievers import ParentDocumentRetrieverAPI Reference:ParentDocumentRetriever\nfrom langchain.storage import InMemoryStorefrom langchain_chroma import Chromafrom langchain_community.document_loaders import TextLoaderfrom langchain_openai import OpenAIEmbeddingsfrom langchain_text_splitters import RecursiveCharacterTextSplitterAPI Reference:InMemoryStore | TextLoader | OpenAIEmbeddings | RecursiveCharacterTextSplitter\nloaders = [    TextLoader(\"paul_graham_essay.txt\"),    TextLoader(\"state_of_the_union.txt\"),]docs = []for loader in loaders:    docs.extend(loader.load())\nRetrieving full documents\u200b\nIn this mode, we want to retrieve the full documents. Therefore, we only specify a child splitter.\n# This text splitter is used to create the child documentschild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)# The vectorstore to use to index the child chunksvectorstore = Chroma(    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings())# The storage layer for the parent documentsstore = InMemoryStore()retriever = ParentDocumentRetriever(    vectorstore=vectorstore,    docstore=store,    child_splitter=child_splitter,)\nretriever.add_documents(docs, ids=None)\nThis should yield two keys, because we added two documents.\nlist(store.yield_keys())\n['9a63376c-58cc-42c9-b0f7-61f0e1a3a688', '40091598-e918-4a18-9be0-f46413a95ae4']\nLet's now call the vector store search functionality - we should see that it returns small chunks (since we're storing the small chunks).\nsub_docs = vectorstore.similarity_search(\"justice breyer\")\nprint(sub_docs[0].page_content)\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\nLet's now retrieve from the overall retriever. This should return large documents - since it returns the documents where the smaller chunks are located.\nretrieved_docs = retriever.invoke(\"justice breyer\")\nlen(retrieved_docs[0].page_content)\n38540\nRetrieving larger chunks\u200b\nSometimes, the full documents can be too big to want to retrieve them as is. In that case, what we really want to do is to first split the raw documents into larger chunks, and then split it into smaller chunks. We then index the smaller chunks, but on retrieval we retrieve the larger chunks (but still not the full documents).\n# This text splitter is used to create the parent documentsparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)# This text splitter is used to create the child documents# It should create documents smaller than the parentchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)# The vectorstore to use to index the child chunksvectorstore = Chroma(    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings())# The storage layer for the parent documentsstore = InMemoryStore()\nretriever = ParentDocumentRetriever(    vectorstore=vectorstore,    docstore=store,    child_splitter=child_splitter,    parent_splitter=parent_splitter,)\nretriever.add_documents(docs)\nWe can see that there are much more than two documents now - these are the larger chunks.\nlen(list(store.yield_keys()))\n66\nLet's make sure the underlying vector store still retrieves the small chunks.\nsub_docs = vectorstore.similarity_search(\"justice breyer\")\nprint(sub_docs[0].page_content)\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\nretrieved_docs = retriever.invoke(\"justice breyer\")\nlen(retrieved_docs[0].page_content)\n1849\nprint(retrieved_docs[0].page_content)\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. We cannot let this happen. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. We can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  We\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  We\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. We\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.Edit this pageWas this page helpful?PreviousHow to parse YAML outputNextHow to use LangChain with different Pydantic versionsRetrieving full documentsRetrieving larger chunksCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright \u00a9 2025 LangChain, Inc.\n\n"
      }
    ]
  }
]